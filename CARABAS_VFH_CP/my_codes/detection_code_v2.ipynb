{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c62f4f",
   "metadata": {},
   "source": [
    "0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7248cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rice, uniform\n",
    "from scipy import ndimage\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeb010b",
   "metadata": {},
   "source": [
    "1. SETUP: Paths, Metadata, and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebe626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TO DO: Update these paths ---\n",
    "IMAGE_DIR = 'images'\n",
    "TARGET_DIR = 'target_lists'\n",
    "PARAM_DIR = 'parameter_maps' # Directory to save/load MLE results\n",
    "\n",
    "# Create parameter map directory if it doesn't exist\n",
    "if not os.path.exists(PARAM_DIR):\n",
    "    os.makedirs(PARAM_DIR)\n",
    "\n",
    "# --- Metadata for all 24 images (from previous steps) ---\n",
    "image_metadata = [\n",
    "    # Mission 2: Deployment \"Sigismund\"\n",
    "    {'mission': 2, 'pass': 1, 'heading': 225, 'deployment': 'Sigismund', 'rfi': 1, 'filename': 'v02_2_1_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 2, 'pass': 2, 'heading': 135, 'deployment': 'Sigismund', 'rfi': 0, 'filename': 'v02_2_2_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 2, 'pass': 3, 'heading': 225, 'deployment': 'Sigismund', 'rfi': 1, 'filename': 'v02_2_3_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 2, 'pass': 4, 'heading': 135, 'deployment': 'Sigismund', 'rfi': 0, 'filename': 'v02_2_4_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 2, 'pass': 5, 'heading': 230, 'deployment': 'Sigismund', 'rfi': 1, 'filename': 'v02_2_5_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 2, 'pass': 6, 'heading': 230, 'deployment': 'Sigismund', 'rfi': 1, 'filename': 'v02_2_6_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    # Mission 3: Deployment \"Karl\"\n",
    "    {'mission': 3, 'pass': 1, 'heading': 225, 'deployment': 'Karl', 'rfi': 1, 'filename': 'v02_3_1_2.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 3, 'pass': 2, 'heading': 135, 'deployment': 'Karl', 'rfi': 0, 'filename': 'v02_3_2_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 3, 'pass': 3, 'heading': 225, 'deployment': 'Karl', 'rfi': 1, 'filename': 'v02_3_3_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 3, 'pass': 4, 'heading': 135, 'deployment': 'Karl', 'rfi': 0, 'filename': 'v02_3_4_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 3, 'pass': 5, 'heading': 230, 'deployment': 'Karl', 'rfi': 1, 'filename': 'v02_3_5_2.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 3, 'pass': 6, 'heading': 230, 'deployment': 'Karl', 'rfi': 1, 'filename': 'v02_3_6_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    # Mission 4: Deployment \"Fredrik\"\n",
    "    {'mission': 4, 'pass': 1, 'heading': 225, 'deployment': 'Fredrik', 'rfi': 1, 'filename': 'v02_4_1_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 4, 'pass': 2, 'heading': 135, 'deployment': 'Fredrik', 'rfi': 0, 'filename': 'v02_4_2_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 4, 'pass': 3, 'heading': 225, 'deployment': 'Fredrik', 'rfi': 1, 'filename': 'v02_4_3_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 4, 'pass': 4, 'heading': 135, 'deployment': 'Fredrik', 'rfi': 0, 'filename': 'v02_4_4_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 4, 'pass': 5, 'heading': 230, 'deployment': 'Fredrik', 'rfi': 1, 'filename': 'v02_4_5_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 4, 'pass': 6, 'heading': 230, 'deployment': 'Fredrik', 'rfi': 1, 'filename': 'v02_4_6_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    # Mission 5: Deployment \"Adolf-Fredrik\"\n",
    "    {'mission': 5, 'pass': 1, 'heading': 225, 'deployment': 'Adolf-Fredrik', 'rfi': 1, 'filename': 'v02_5_1_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 5, 'pass': 2, 'heading': 135, 'deployment': 'Adolf-Fredrik', 'rfi': 0, 'filename': 'v02_5_2_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 5, 'pass': 3, 'heading': 225, 'deployment': 'Adolf-Fredrik', 'rfi': 1, 'filename': 'v02_5_3_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 5, 'pass': 4, 'heading': 135, 'deployment': 'Adolf-Fredrik', 'rfi': 0, 'filename': 'v02_5_4_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 5, 'pass': 5, 'heading': 230, 'deployment': 'Adolf-Fredrik', 'rfi': 1, 'filename': 'v02_5_5_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "    {'mission': 5, 'pass': 6, 'heading': 230, 'deployment': 'Adolf-Fredrik', 'rfi': 1, 'filename': 'v02_5_6_1.a.Fbp.RFcorr.Geo.Magn'},\n",
    "]\n",
    "epsilon = 1e-9 # Small constant to prevent division by zero or log(0)\n",
    "\n",
    "def load_sar_image(filename, directory, rows=3000, cols=2000):\n",
    "    \"\"\"Reads a raw 32-bit big-endian float CARABAS-II image file.\"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    image_data = np.fromfile(filepath, dtype='>f4').reshape((rows, cols))\n",
    "    return image_data\n",
    "\n",
    "def load_ground_truth_pixels(deployment_name, target_dir):\n",
    "    \"\"\"Loads and converts ground truth coordinates to pixel locations.\"\"\"\n",
    "    target_filename = deployment_name + \".Targets.txt\"\n",
    "    target_filepath = os.path.join(target_dir, target_filename)\n",
    "    \n",
    "    ground_truth_geo = np.loadtxt(target_filepath, usecols=(0, 1))\n",
    "    \n",
    "    # Constants from data_description.pdf\n",
    "    Nmax, Emin = 7370488, 1653166\n",
    "    \n",
    "    ground_truth_pixels = []\n",
    "    for north, east in ground_truth_geo:\n",
    "        row = int(round(Nmax - north))\n",
    "        col = int(round(east - Emin))\n",
    "        ground_truth_pixels.append((row, col))\n",
    "        \n",
    "    return ground_truth_pixels\n",
    "\n",
    "def evaluate_performance(detection_map, ground_truth_pixels):\n",
    "    \"\"\"Calculates Pd and FAR for a given detection map.\"\"\"\n",
    "    # Post-process the map: one erosion, two dilations\n",
    "    eroded_map = ndimage.binary_erosion(detection_map)\n",
    "    processed_map = ndimage.binary_dilation(eroded_map, iterations=2)\n",
    "    \n",
    "    # Find the center of each detected object\n",
    "    labeled_map, num_objects = ndimage.label(processed_map)\n",
    "    if num_objects == 0:\n",
    "        return 0.0, 0.0 # No detections, so Pd=0 and FAR=0\n",
    "        \n",
    "    detected_centers = ndimage.center_of_mass(processed_map, labeled_map, range(1, num_objects + 1))\n",
    "    \n",
    "    # Match detections to ground truth targets\n",
    "    match_radius = 10.0\n",
    "    true_positives = 0\n",
    "    unmatched_detections = list(detected_centers)\n",
    "    num_true_targets = len(ground_truth_pixels)\n",
    "    \n",
    "    for true_target_pos in ground_truth_pixels:\n",
    "        for i, detected_pos in enumerate(unmatched_detections):\n",
    "            distance = np.sqrt((true_target_pos[0] - detected_pos[0])**2 + (true_target_pos[1] - detected_pos[1])**2)\n",
    "            if distance <= match_radius:\n",
    "                true_positives += 1\n",
    "                unmatched_detections.pop(i)\n",
    "                break\n",
    "    \n",
    "    false_positives = len(unmatched_detections)\n",
    "    image_area_km2 = 6.0\n",
    "    \n",
    "    pd = true_positives / num_true_targets if num_true_targets > 0 else 0.0\n",
    "    far = false_positives / image_area_km2\n",
    "    \n",
    "    return pd, far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89fe39f",
   "metadata": {},
   "source": [
    "2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Data Preparation ---\")\n",
    "# Select surveillance image and build background stack\n",
    "surveillance_info = image_metadata[0]\n",
    "background_stack_info = [\n",
    "    img for img in image_metadata\n",
    "    if img['heading'] == surveillance_info['heading']\n",
    "    and img['deployment'] != surveillance_info['deployment']\n",
    "]\n",
    "\n",
    "print(f\"Surveillance Image: {surveillance_info['filename']}\")\n",
    "surveillance_image = load_sar_image(surveillance_info['filename'], IMAGE_DIR)\n",
    "background_images = [load_sar_image(info['filename'], IMAGE_DIR) for info in background_stack_info]\n",
    "background_stack = np.stack(background_images, axis=0)\n",
    "\n",
    "# Load ground truth for this surveillance image\n",
    "ground_truth = load_ground_truth_pixels(surveillance_info['deployment'], TARGET_DIR)\n",
    "print(f\"Loaded {len(ground_truth)} ground truth targets for {surveillance_info['deployment']}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1e451",
   "metadata": {},
   "source": [
    "3. Rician Background Modeling (MLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f79a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Rician Background Modeling ---\")\n",
    "B_MAP_FILE = os.path.join(PARAM_DIR, 'b_map.npy')\n",
    "LOC_MAP_FILE = os.path.join(PARAM_DIR, 'loc_map.npy')\n",
    "SCALE_MAP_FILE = os.path.join(PARAM_DIR, 'scale_map.npy')\n",
    "\n",
    "if os.path.exists(B_MAP_FILE):\n",
    "    print(\"Loading pre-calculated Rician parameter maps...\")\n",
    "    b_map = np.load(B_MAP_FILE)\n",
    "    loc_map = np.load(LOC_MAP_FILE)\n",
    "    scale_map = np.load(SCALE_MAP_FILE)\n",
    "else:\n",
    "    print(\"Performing Rician MLE fit for the entire image. THIS WILL TAKE SEVERAL HOURS.\")\n",
    "    start_time = time.time()\n",
    "    rows, cols = surveillance_image.shape\n",
    "    b_map, loc_map, scale_map = np.zeros((3, rows, cols))\n",
    "    \n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            pixel_data = background_stack[:, r, c]\n",
    "            b, loc, scale = rice.fit(pixel_data, floc=0)\n",
    "            b_map[r, c], loc_map[r, c], scale_map[r, c] = b, loc, scale\n",
    "        if (r + 1) % 100 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Processed row {r+1}/{rows}... Time: {elapsed/60:.2f} min.\")\n",
    "    \n",
    "    print(\"MLE fitting complete. Saving maps to disk...\")\n",
    "    np.save(B_MAP_FILE, b_map)\n",
    "    np.save(LOC_MAP_FILE, loc_map)\n",
    "    np.save(SCALE_MAP_FILE, scale_map)\n",
    "print(\"Background model is ready.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8dee16",
   "metadata": {},
   "source": [
    "4. ROC Curve Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- ROC Curve Generation ---\")\n",
    "# Define the thresholds to test\n",
    "pfa_thresholds = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "tau_thresholds = [1, 10, 100, 1000, 1e4, 1e5, 1e6]\n",
    "\n",
    "npcbs_results = []\n",
    "npc_results = []\n",
    "\n",
    "# --- Method 1: NPCBS ---\n",
    "print(\"Running NPCBS method for different P_FA thresholds...\")\n",
    "for p_fa in pfa_thresholds:\n",
    "    detection_threshold = 1 - p_fa\n",
    "    cdf_values = rice.cdf(surveillance_image, b_map, loc=loc_map, scale=(scale_map + epsilon))\n",
    "    detection_map = cdf_values >= detection_threshold\n",
    "    \n",
    "    pd, far = evaluate_performance(detection_map, ground_truth)\n",
    "    npcbs_results.append((far, pd))\n",
    "    print(f\"  P_FA={p_fa:.0e} -> Pd={pd:.2%}, FAR={far:.2f}\")\n",
    "\n",
    "# --- Method 2: NPC ---\n",
    "print(\"\\nRunning NPC method for different Tau thresholds...\")\n",
    "# Target model: Uniform distribution\n",
    "a_min = 0.4 # From paper's suggestion\n",
    "a_max = np.max(surveillance_image)\n",
    "\n",
    "# Calculate PDFs (vectorized for speed)\n",
    "p_background = rice.pdf(surveillance_image, b_map, loc=loc_map, scale=(scale_map + epsilon))\n",
    "p_target = uniform.pdf(surveillance_image, loc=a_min, scale=(a_max - a_min))\n",
    "\n",
    "# Likelihood Ratio\n",
    "likelihood_ratio = p_target / (p_background + epsilon)\n",
    "\n",
    "for tau in tau_thresholds:\n",
    "    detection_map = likelihood_ratio >= tau\n",
    "    pd, far = evaluate_performance(detection_map, ground_truth)\n",
    "    npc_results.append((far, pd))\n",
    "    print(f\"  Tau={tau:.0e} -> Pd={pd:.2%}, FAR={far:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ce8cd",
   "metadata": {},
   "source": [
    "5. Plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Plotting ROC Curve ---\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Unzip results for plotting\n",
    "npcbs_far, npcbs_pd = zip(*npcbs_results)\n",
    "npc_far, npc_pd = zip(*npc_results)\n",
    "\n",
    "plt.plot(npcbs_far, npcbs_pd, 'o-', label='NPCBS Method')\n",
    "plt.plot(npc_far, npc_pd, 's-', label='NPC Method (a_min=0.4)')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.xlabel('False Alarm Rate (FAR) [alarms/kmÂ²]')\n",
    "plt.ylabel('Probability of Detection (Pd)')\n",
    "plt.title('ROC Curve Comparison for Change Detection Methods')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xlim(1e-2, 1e2) # Set x-axis limits similar to the paper\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
